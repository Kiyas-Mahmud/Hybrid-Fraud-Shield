{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b20278d",
   "metadata": {},
   "source": [
    "# Complete ML Pipeline - Fraud Detection\n",
    "\n",
    "**Phases:**\n",
    "1. Data Preparation (72 features)\n",
    "2. Base Model Training (5 models)\n",
    "3. Hyperparameter Tuning\n",
    "4. Model Evaluation\n",
    "5. Threshold Optimization\n",
    "6. Model Persistence\n",
    "7. Visualization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ea2327",
   "metadata": {},
   "source": [
    "## Phase 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2140f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3273650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('../../data/reduced_df.csv')\n",
    "print(f\"Dataset loaded: {data.shape}\")\n",
    "\n",
    "# Check nulls and duplicates\n",
    "print(f\"Null values: {data.isnull().sum().sum()}\")\n",
    "print(f\"Duplicates: {data.duplicated().sum()}\")\n",
    "\n",
    "# Remove duplicates if any\n",
    "data = data.drop_duplicates()\n",
    "print(f\"Final dataset: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50a5a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = data.drop('isFraud', axis=1)\n",
    "y = data['isFraud']\n",
    "\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Samples: {X.shape[0]}\")\n",
    "print(f\"Fraud rate: {y.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7696157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (80-20 stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]} samples\")\n",
    "print(f\"Test: {X_test.shape[0]} samples\")\n",
    "print(f\"Train fraud rate: {y_train.mean()*100:.2f}%\")\n",
    "print(f\"Test fraud rate: {y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f003e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling for Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(\"Scaling completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c94773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE for Random Forest\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "print(f\"SMOTE samples: {X_train_smote.shape[0]}\")\n",
    "print(f\"SMOTE fraud rate: {y_train_smote.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0e9f04",
   "metadata": {},
   "source": [
    "## Phase 2: Base Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f76ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, f1_score, precision_score, \n",
    "    recall_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "print(\"Model libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd74181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, y_true, y_pred, y_pred_proba):\n",
    "    results = {\n",
    "        'Model': name,\n",
    "        'ROC-AUC': roc_auc_score(y_true, y_pred_proba),\n",
    "        'F1-Score': f1_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_true, y_pred, zero_division=0)\n",
    "    }\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"ROC-AUC: {results['ROC-AUC']:.4f}\")\n",
    "    print(f\"F1-Score: {results['F1-Score']:.4f}\")\n",
    "    print(f\"Precision: {results['Precision']:.4f}\")\n",
    "    print(f\"Recall: {results['Recall']:.4f}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0509b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scale_pos_weight for XGBoost\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"Scale pos weight: {scale_pos_weight:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7d6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = []\n",
    "\n",
    "# XGBoost\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_base = XGBClassifier(scale_pos_weight=scale_pos_weight, random_state=42, eval_metric='logloss')\n",
    "xgb_base.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_base.predict(X_test)\n",
    "y_pred_proba_xgb = xgb_base.predict_proba(X_test)[:, 1]\n",
    "baseline_results.append(evaluate_model('XGBoost', y_test, y_pred_xgb, y_pred_proba_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost\n",
    "print(\"Training CatBoost...\")\n",
    "cat_base = CatBoostClassifier(auto_class_weights='Balanced', random_state=42, verbose=False)\n",
    "cat_base.fit(X_train, y_train)\n",
    "y_pred_cat = cat_base.predict(X_test)\n",
    "y_pred_proba_cat = cat_base.predict_proba(X_test)[:, 1]\n",
    "baseline_results.append(evaluate_model('CatBoost', y_test, y_pred_cat, y_pred_proba_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088e2f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "print(\"Training LightGBM...\")\n",
    "lgbm_base = LGBMClassifier(class_weight='balanced', random_state=42, verbose=-1)\n",
    "lgbm_base.fit(X_train, y_train)\n",
    "y_pred_lgbm = lgbm_base.predict(X_test)\n",
    "y_pred_proba_lgbm = lgbm_base.predict_proba(X_test)[:, 1]\n",
    "baseline_results.append(evaluate_model('LightGBM', y_test, y_pred_lgbm, y_pred_proba_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e79bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with SMOTE\n",
    "print(\"Training Random Forest...\")\n",
    "rf_base = RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "rf_base.fit(X_train_smote, y_train_smote)\n",
    "y_pred_rf = rf_base.predict(X_test)\n",
    "y_pred_proba_rf = rf_base.predict_proba(X_test)[:, 1]\n",
    "baseline_results.append(evaluate_model('RandomForest', y_test, y_pred_rf, y_pred_proba_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b65eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr_base = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "lr_base.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr_base.predict(X_test_scaled)\n",
    "y_pred_proba_lr = lr_base.predict_proba(X_test_scaled)[:, 1]\n",
    "baseline_results.append(evaluate_model('LogisticRegression', y_test, y_pred_lr, y_pred_proba_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ac56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = pd.DataFrame(baseline_results)\n",
    "print(\"\\nBaseline Results:\")\n",
    "print(baseline_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40753376",
   "metadata": {},
   "source": [
    "## Phase 3: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386654d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "print(\"Search libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aee8476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost tuning\n",
    "print(\"Tuning XGBoost...\")\n",
    "xgb_params = {\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [200, 400, 600],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    XGBClassifier(scale_pos_weight=scale_pos_weight, random_state=42, eval_metric='logloss'),\n",
    "    xgb_params,\n",
    "    n_iter=20,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_search.fit(X_train, y_train)\n",
    "print(f\"Best XGBoost params: {xgb_search.best_params_}\")\n",
    "xgb_tuned = xgb_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88769c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost tuning\n",
    "print(\"Tuning CatBoost...\")\n",
    "cat_params = {\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'iterations': [500, 1000],\n",
    "    'learning_rate': [0.03, 0.1],\n",
    "    'l2_leaf_reg': [1, 3, 5]\n",
    "}\n",
    "\n",
    "cat_search = RandomizedSearchCV(\n",
    "    CatBoostClassifier(auto_class_weights='Balanced', random_state=42, verbose=False),\n",
    "    cat_params,\n",
    "    n_iter=15,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "cat_search.fit(X_train, y_train)\n",
    "print(f\"Best CatBoost params: {cat_search.best_params_}\")\n",
    "cat_tuned = cat_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edab55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM tuning\n",
    "print(\"Tuning LightGBM...\")\n",
    "lgbm_params = {\n",
    "    'num_leaves': [31, 63],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [200, 400],\n",
    "    'subsample': [0.7, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.9]\n",
    "}\n",
    "\n",
    "lgbm_search = RandomizedSearchCV(\n",
    "    LGBMClassifier(class_weight='balanced', random_state=42, verbose=-1),\n",
    "    lgbm_params,\n",
    "    n_iter=15,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lgbm_search.fit(X_train, y_train)\n",
    "print(f\"Best LightGBM params: {lgbm_search.best_params_}\")\n",
    "lgbm_tuned = lgbm_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f17bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest tuning\n",
    "print(\"Tuning Random Forest...\")\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "    rf_params,\n",
    "    n_iter=15,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_search.fit(X_train_smote, y_train_smote)\n",
    "print(f\"Best RF params: {rf_search.best_params_}\")\n",
    "rf_tuned = rf_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f987efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression tuning\n",
    "print(\"Tuning Logistic Regression...\")\n",
    "lr_params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs']\n",
    "}\n",
    "\n",
    "lr_search = GridSearchCV(\n",
    "    LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),\n",
    "    lr_params,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lr_search.fit(X_train_scaled, y_train)\n",
    "print(f\"Best LR params: {lr_search.best_params_}\")\n",
    "lr_tuned = lr_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc12784c",
   "metadata": {},
   "source": [
    "## Phase 4: Post-Tuning Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ccfbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_results = []\n",
    "\n",
    "# Evaluate tuned models\n",
    "y_pred_xgb_t = xgb_tuned.predict(X_test)\n",
    "y_pred_proba_xgb_t = xgb_tuned.predict_proba(X_test)[:, 1]\n",
    "tuned_results.append(evaluate_model('XGBoost_Tuned', y_test, y_pred_xgb_t, y_pred_proba_xgb_t))\n",
    "\n",
    "y_pred_cat_t = cat_tuned.predict(X_test)\n",
    "y_pred_proba_cat_t = cat_tuned.predict_proba(X_test)[:, 1]\n",
    "tuned_results.append(evaluate_model('CatBoost_Tuned', y_test, y_pred_cat_t, y_pred_proba_cat_t))\n",
    "\n",
    "y_pred_lgbm_t = lgbm_tuned.predict(X_test)\n",
    "y_pred_proba_lgbm_t = lgbm_tuned.predict_proba(X_test)[:, 1]\n",
    "tuned_results.append(evaluate_model('LightGBM_Tuned', y_test, y_pred_lgbm_t, y_pred_proba_lgbm_t))\n",
    "\n",
    "y_pred_rf_t = rf_tuned.predict(X_test)\n",
    "y_pred_proba_rf_t = rf_tuned.predict_proba(X_test)[:, 1]\n",
    "tuned_results.append(evaluate_model('RandomForest_Tuned', y_test, y_pred_rf_t, y_pred_proba_rf_t))\n",
    "\n",
    "y_pred_lr_t = lr_tuned.predict(X_test_scaled)\n",
    "y_pred_proba_lr_t = lr_tuned.predict_proba(X_test_scaled)[:, 1]\n",
    "tuned_results.append(evaluate_model('LogisticRegression_Tuned', y_test, y_pred_lr_t, y_pred_proba_lr_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e5dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_df = pd.DataFrame(tuned_results)\n",
    "print(\"\\nTuned Results:\")\n",
    "print(tuned_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5dca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline vs tuned\n",
    "comparison = pd.concat([baseline_df, tuned_df], ignore_index=True)\n",
    "comparison.to_csv('results/baseline_vs_tuned.csv', index=False)\n",
    "print(\"\\nComparison saved to results/baseline_vs_tuned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d6c566",
   "metadata": {},
   "source": [
    "## Phase 5: Threshold Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2efd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def find_best_threshold(y_true, y_pred_proba):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred_proba)\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n",
    "    best_f1 = f1_scores[best_idx]\n",
    "    return best_threshold, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db69a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {}\n",
    "\n",
    "# Find optimal thresholds for each model\n",
    "models_proba = [\n",
    "    ('XGBoost', y_pred_proba_xgb_t),\n",
    "    ('CatBoost', y_pred_proba_cat_t),\n",
    "    ('LightGBM', y_pred_proba_lgbm_t),\n",
    "    ('RandomForest', y_pred_proba_rf_t),\n",
    "    ('LogisticRegression', y_pred_proba_lr_t)\n",
    "]\n",
    "\n",
    "for name, proba in models_proba:\n",
    "    best_thresh, best_f1 = find_best_threshold(y_test, proba)\n",
    "    thresholds[name] = {'threshold': float(best_thresh), 'f1_score': float(best_f1)}\n",
    "    print(f\"{name}: Threshold={best_thresh:.3f}, F1={best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd19fe75",
   "metadata": {},
   "source": [
    "## Phase 6: Save Final Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84bf5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Save models\n",
    "models = {\n",
    "    'xgboost': xgb_tuned,\n",
    "    'catboost': cat_tuned,\n",
    "    'lightgbm': lgbm_tuned,\n",
    "    'randomforest': rf_tuned,\n",
    "    'logistic_regression': lr_tuned\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    with open(f'new_models/{name}_model.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Saved {name}_model.pkl\")\n",
    "\n",
    "# Save scaler\n",
    "with open('new_models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"Saved scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bda5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata\n",
    "metadata = {\n",
    "    'date': datetime.now().isoformat(),\n",
    "    'n_features': X.shape[1],\n",
    "    'n_train_samples': X_train.shape[0],\n",
    "    'n_test_samples': X_test.shape[0],\n",
    "    'fraud_rate': float(y.mean()),\n",
    "    'thresholds': thresholds,\n",
    "    'best_params': {\n",
    "        'xgboost': xgb_search.best_params_,\n",
    "        'catboost': cat_search.best_params_,\n",
    "        'lightgbm': lgbm_search.best_params_,\n",
    "        'randomforest': rf_search.best_params_,\n",
    "        'logistic_regression': lr_search.best_params_\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('new_models/metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(\"Saved metadata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0afc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature list\n",
    "feature_list = X.columns.tolist()\n",
    "with open('new_models/features.json', 'w') as f:\n",
    "    json.dump({'features': feature_list}, f, indent=2)\n",
    "print(f\"Saved features.json ({len(feature_list)} features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d89d1",
   "metadata": {},
   "source": [
    "## Phase 7: Visualization and Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840661b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca688b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for XGBoost\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': xgb_tuned.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(20)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Features - XGBoost')\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/feature_importance.png', dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved feature_importance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a6845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "models_pred = [\n",
    "    ('XGBoost', y_pred_xgb_t),\n",
    "    ('CatBoost', y_pred_cat_t),\n",
    "    ('LightGBM', y_pred_lgbm_t),\n",
    "    ('RandomForest', y_pred_rf_t),\n",
    "    ('LogisticRegression', y_pred_lr_t)\n",
    "]\n",
    "\n",
    "for idx, (name, pred) in enumerate(models_pred):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "\n",
    "axes[1, 2].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/confusion_matrices.png', dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved confusion_matrices.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ae44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison bar chart\n",
    "comparison_plot = tuned_df.set_index('Model')\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "comparison_plot['F1-Score'].plot(kind='bar', ax=axes[0], color='skyblue')\n",
    "axes[0].set_title('F1-Score Comparison')\n",
    "axes[0].set_ylabel('F1-Score')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "comparison_plot['Recall'].plot(kind='bar', ax=axes[1], color='lightgreen')\n",
    "axes[1].set_title('Recall Comparison')\n",
    "axes[1].set_ylabel('Recall')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "comparison_plot['ROC-AUC'].plot(kind='bar', ax=axes[2], color='coral')\n",
    "axes[2].set_title('ROC-AUC Comparison')\n",
    "axes[2].set_ylabel('ROC-AUC')\n",
    "axes[2].set_xticklabels(axes[2].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/model_comparison.png', dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved model_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98e3da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, proba in models_proba:\n",
    "    fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "    auc = roc_auc_score(y_test, proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC={auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves - All Models')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/roc_curves.png', dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved roc_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fb1906",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PIPELINE COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nSaved:\")\n",
    "print(\"- 5 trained models (new_models/)\")\n",
    "print(\"- Scaler (new_models/)\")\n",
    "print(\"- Metadata with thresholds (new_models/)\")\n",
    "print(\"- Feature list (new_models/)\")\n",
    "print(\"- Results CSV (results/)\")\n",
    "print(\"- 4 visualizations (visualizations/)\")\n",
    "print(\"\\nReady for deployment!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
